{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "31aef046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并后表中的空值数目： 9\n",
      "   USER_ID  frequence  numbers   amount ACCOUNT      LAST_VISITS type\n",
      "0     2361         41    237.0  34784.0     薛浩天  2016/7/30 13:29  非流失\n",
      "1     3768         33    207.0  32699.0     易之赫  2016/7/28 12:24  非流失\n",
      "2     3762         33    208.0  30394.0     许智蕴  2016/7/27 13:41  非流失\n",
      "3     2147         32    192.0  27088.0     萧郁丁  2016/7/25 12:34  非流失\n",
      "4     1131         25    116.0  18910.0      夏晴  2016/7/25 11:35  非流失\n",
      "   USER_ID ACCOUNT  frequence   amount average  recently type\n",
      "0     2361     薛浩天         41  34784.0  146.77         0  非流失\n",
      "1     3768     易之赫         33  32699.0  157.97         2  非流失\n",
      "2     3762     许智蕴         33  30394.0  146.12         3  非流失\n",
      "3     2147     萧郁丁         32  27088.0  141.08         5  非流失\n",
      "4     1131      夏晴         25  18910.0  163.02         5  非流失\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "info_user = pd.read_csv('test.csv', encoding='gbk')\n",
    "\n",
    "# 提取info表的用户名和用餐时间，并按人名对用餐人数和金额进行分组求和\n",
    "info_user1 = info_user['USER_ID'].value_counts()  # 按USER_ID统计出现的次数\n",
    "info_user1 = info_user1.reset_index() # 将分组结果重置索引\n",
    "info_user1.columns = ['USER_ID', 'frequence']  # 重命名列为USER_ID和frenqunce\n",
    "\n",
    "# 求出每个人的消费总金额\n",
    "info_user2 = info_user[['number_consumers', \"expenditure\"]].groupby(info_user['USER_ID']).sum()  # 按USER_ID分组，计算number_consumers和expenditure的总和\n",
    "info_user2 = info_user2.reset_index()\n",
    "info_user2.columns = ['USER_ID', 'numbers', 'amount']  # 重命名列\n",
    "\n",
    "# 合并用户的用餐频次和总消费信息\n",
    "info_user_new = pd.merge(info_user1, info_user2, left_on='USER_ID', right_on='USER_ID', how='left') \n",
    "\n",
    "# 对合并后的数据进行处理\n",
    "info_user = info_user.iloc[:, :4]  # 选择前四列\n",
    "info_user = info_user.groupby(['USER_ID']).last()  # 按USER_ID分组，选择每组的最后一个\n",
    "info_user = info_user.reset_index()  # 重置索引\n",
    "\n",
    "# 合并用餐频次、总消费信息和最近一次用餐信息\n",
    "info_user_new = pd.merge(info_user_new, info_user, left_on='USER_ID', right_on='USER_ID', how='left')\n",
    "\n",
    "print('合并后表中的空值数目：', info_user_new.isnull().sum().sum())\n",
    "info_user_new = info_user_new.dropna(axis=0)  # 删除包含空值的行\n",
    "info_user_new = info_user_new[info_user_new['numbers'] != 0] # 过滤掉用餐总人数为0的行\n",
    "print(info_user_new.head())\n",
    "\n",
    "# 计算每个用户的平均消费金额\n",
    "info_user_new['average'] = info_user_new['amount']/info_user_new['numbers']\n",
    "info_user_new['average'] = info_user_new['average'].apply(lambda x: '%.2f' % x)\n",
    "\n",
    "# 计算每个客户最近一次点餐的时间距离观测窗口结束的天数\n",
    "# 修改时间列，改为日期\n",
    "info_user_new['LAST_VISITS'] = pd.to_datetime(info_user_new['LAST_VISITS'])\n",
    "datefinally = pd.to_datetime('2016-7-31')  # 观测窗口结束时间\n",
    "time = datefinally - info_user_new['LAST_VISITS']\n",
    "info_user_new['recently'] = time.apply(lambda x: x.days)   # 计算时间差\n",
    "\n",
    "# 选择需要输出的列并保存为新的csv文件\n",
    "info_user_new = info_user_new.loc[:, ['USER_ID', 'ACCOUNT', 'frequence', 'amount', 'average', 'recently', 'type']]\n",
    "info_user_new.to_csv('test-after.csv', index=False, encoding='gbk')\n",
    "print(info_user_new.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5219fb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理和特征构造\n",
    "def preprocess_data(data):\n",
    "    data['LAST_VISITS'] = pd.to_datetime(data['LAST_VISITS'])\n",
    "    datefinally = pd.to_datetime('2016-7-31')\n",
    "    data['recently'] = (datefinally - data['LAST_VISITS']).dt.days\n",
    "    \n",
    "    user_counts = data['USER_ID'].value_counts().reset_index()\n",
    "    user_counts.columns = ['USER_ID', 'frequence']\n",
    "    \n",
    "    user_sums = data[['USER_ID', 'number_consumers', 'expenditure']].groupby('USER_ID').sum().reset_index()\n",
    "    user_sums.columns = ['USER_ID', 'numbers', 'amount']\n",
    "    \n",
    "    data_new = pd.merge(user_counts, user_sums, on='USER_ID', how='left')\n",
    "    data_new = pd.merge(data_new, data[['USER_ID', 'ACCOUNT', 'type', 'recently']].drop_duplicates(), on='USER_ID', how='left')\n",
    "    \n",
    "    data_new = data_new.dropna(axis=0)\n",
    "    data_new = data_new[data_new['numbers'] != 0]\n",
    "    \n",
    "    data_new['average'] = data_new['amount'] / data_new['numbers']\n",
    "    data_new['average'] = data_new['average'].apply(lambda x: float('%.2f' % x))\n",
    "    \n",
    "    return data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a7e8f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取训练数据和测试数据\n",
    "train_data = pd.read_csv('train.csv', encoding='gbk')\n",
    "test_data = pd.read_csv('test.csv', encoding='gbk')\n",
    "\n",
    "# 预处理训练数据和测试数据\n",
    "train_data_new = preprocess_data(train_data)\n",
    "test_data_new = preprocess_data(test_data)\n",
    "\n",
    "# 准备训练数据和标签\n",
    "X_train = train_data_new[['frequence', 'recently', 'average', 'amount']]\n",
    "y_train = train_data_new['type']\n",
    "\n",
    "# 准备测试数据和标签\n",
    "X_test = test_data_new[['frequence', 'recently', 'average', 'amount']]\n",
    "y_test = test_data_new['type']\n",
    "\n",
    "# 数据标准化\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e5de7b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree - Best Parameters: {'max_depth': 40, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Decision Tree - Best CV Accuracy: 0.9105074462217321\n",
      "Decision Tree with Best Params - Train Accuracy: 0.9749661705006766, Test Accuracy: 0.8986175115207373\n"
     ]
    }
   ],
   "source": [
    "# 2、使用决策树模型做预测\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# 参数网格\n",
    "param_grid_tree = {\n",
    "    'max_depth': [None, 10, 20, 30, 40, 50],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 8],\n",
    "}\n",
    "\n",
    "# 决策树模型\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# 网格搜索\n",
    "grid_search_tree = GridSearchCV(estimator=tree, param_grid=param_grid_tree, cv=10)\n",
    "grid_search_tree.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 最佳参数和准确率\n",
    "best_params_tree = grid_search_tree.best_params_\n",
    "best_score_tree = grid_search_tree.best_score_\n",
    "\n",
    "print(f'Decision Tree - Best Parameters: {best_params_tree}')\n",
    "print(f'Decision Tree - Best CV Accuracy: {best_score_tree}')\n",
    "\n",
    "# 使用最佳参数进行预测\n",
    "best_tree = grid_search_tree.best_estimator_\n",
    "y_pred_train_best_tree = best_tree.predict(X_train_scaled)\n",
    "y_pred_test_best_tree = best_tree.predict(X_test_scaled)\n",
    "\n",
    "# 计算准确率\n",
    "train_accuracy_best_tree = accuracy_score(y_train, y_pred_train_best_tree)\n",
    "test_accuracy_best_tree = accuracy_score(y_test, y_pred_test_best_tree)\n",
    "\n",
    "print(f'Decision Tree with Best Params - Train Accuracy: {train_accuracy_best_tree}, Test Accuracy: {test_accuracy_best_tree}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "9290c5d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN - Best Parameters: {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'uniform'}\n",
      "KNN - Best CV Accuracy: 0.9044493473064902\n",
      "KNN with Best Params - Train Accuracy: 0.9546684709066305, Test Accuracy: 0.9055299539170507\n"
     ]
    }
   ],
   "source": [
    "# 3、使用KNN模型做预测\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# 参数网格\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski']\n",
    "}\n",
    "\n",
    "# KNN模型\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# 网格搜索\n",
    "grid_search_knn = GridSearchCV(estimator=knn, param_grid=param_grid_knn, cv=10)\n",
    "grid_search_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 最佳参数和准确率\n",
    "best_params_knn = grid_search_knn.best_params_\n",
    "best_score_knn = grid_search_knn.best_score_\n",
    "\n",
    "print(f'KNN - Best Parameters: {best_params_knn}')\n",
    "print(f'KNN - Best CV Accuracy: {best_score_knn}')\n",
    "\n",
    "# 使用最佳参数进行预测\n",
    "best_knn = grid_search_knn.best_estimator_\n",
    "y_pred_train_best_knn = best_knn.predict(X_train_scaled)\n",
    "y_pred_test_best_knn = best_knn.predict(X_test_scaled)\n",
    "\n",
    "# 计算准确率\n",
    "train_accuracy_best_knn = accuracy_score(y_train, y_pred_train_best_knn)\n",
    "test_accuracy_best_knn = accuracy_score(y_test, y_pred_test_best_knn)\n",
    "\n",
    "print(f'KNN with Best Params - Train Accuracy: {train_accuracy_best_knn}, Test Accuracy: {test_accuracy_best_knn}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "359818e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4、使用支持向量机做预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fe36b277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: linear - Train Accuracy: 0.9519621109607578, Test Accuracy: 0.923963133640553\n",
      "Kernel: rbf - Train Accuracy: 0.922192151556157, Test Accuracy: 0.8963133640552995\n",
      "Kernel: poly - Train Accuracy: 0.9147496617050067, Test Accuracy: 0.8870967741935484\n",
      "Kernel: sigmoid - Train Accuracy: 0.7706359945872802, Test Accuracy: 0.7396313364055299\n"
     ]
    }
   ],
   "source": [
    "#（1）比较4种核函数的分类准确率\n",
    "# 分别使用4种核函数（线性核、多项式核、高斯核和Sigmoid核）对该数据集进行分类，最后比较4种核函数的分类准确率\n",
    "# 输出所有参数组合的准确率\n",
    "\n",
    "# 核函数比较\n",
    "def evaluate_kernel(kernel_type):\n",
    "    svc = SVC(kernel=kernel_type, decision_function_shape='ovo')\n",
    "    svc.fit(X_train, y_train)\n",
    "    y_pred_train = svc.predict(X_train)\n",
    "    y_pred_test = svc.predict(X_test)\n",
    "    train_accuracy = accuracy_score(y_train, y_pred_train)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred_test)\n",
    "    return train_accuracy, test_accuracy\n",
    "\n",
    "kernels = ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "\n",
    "for kernel in kernels:\n",
    "    train_acc, test_acc = evaluate_kernel(kernel)\n",
    "    print(f'Kernel: {kernel} - Train Accuracy: {train_acc}, Test Accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "03127995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without scaling - Train Accuracy: 0.922192151556157, Test Accuracy: 0.8963133640552995\n",
      "With scaling - Train Accuracy: 0.9512855209742895, Test Accuracy: 0.9400921658986175\n"
     ]
    }
   ],
   "source": [
    "#（2）数据标准化对支持向量机分类准确率的影响\n",
    "# 不进行标准化的数据集\n",
    "svc = SVC(kernel='rbf', decision_function_shape='ovo')\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred_train = svc.predict(X_train)\n",
    "y_pred_test = svc.predict(X_test)\n",
    "train_accuracy_no_scaling = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy_no_scaling = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f'Without scaling - Train Accuracy: {train_accuracy_no_scaling}, Test Accuracy: {test_accuracy_no_scaling}')\n",
    "\n",
    "# 进行标准化的数据集\n",
    "svc.fit(X_train_scaled, y_train)\n",
    "y_pred_train = svc.predict(X_train_scaled)\n",
    "y_pred_test = svc.predict(X_test_scaled)\n",
    "train_accuracy_scaling = accuracy_score(y_train, y_pred_train)\n",
    "test_accuracy_scaling = accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "print(f'With scaling - Train Accuracy: {train_accuracy_scaling}, Test Accuracy: {test_accuracy_scaling}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8a615b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#（3）高斯核函数、多项式核函数的参数调节"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6b7ce4a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF Kernel - Best Parameters: {'gamma': 0.01}\n",
      "RBF Kernel - Best Accuracy: 0.9057915057915059\n"
     ]
    }
   ],
   "source": [
    "#（3.1）高斯核函数的参数调节\n",
    "# 高斯核函数只有一个参数γ的值可调节。\n",
    "\n",
    "# 高斯核函数参数调节\n",
    "param_grid_rbf = {\n",
    "    'gamma': [0.01, 0.1, 1]\n",
    "}\n",
    "\n",
    "svc_rbf = SVC(kernel='rbf', decision_function_shape='ovo')\n",
    "grid_search_rbf = GridSearchCV(estimator=svc_rbf, param_grid=param_grid_rbf, cv=10)\n",
    "grid_search_rbf.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"RBF Kernel - Best Parameters:\", grid_search_rbf.best_params_)\n",
    "print(\"RBF Kernel - Best Accuracy:\", grid_search_rbf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5b0a98b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polynomial Kernel - Best Parameters: {'degree': 3, 'gamma': 1}\n",
      "Polynomial Kernel - Best Accuracy: 0.8660047802904944\n"
     ]
    }
   ],
   "source": [
    "#（3.2）多项式核函数参数的调节\n",
    "# 对于多项式核函数来说，它有三个参数共同作用在一个公式上影响其分类准确率，因此只能使用网格搜索法来功能调整三个对多项式函数有影响的参数\n",
    "param_grid_poly = {\n",
    "    'gamma': [0.01, 0.1, 1],\n",
    "    'degree': [2, 3, 4]\n",
    "}\n",
    "\n",
    "svc_poly = SVC(kernel='poly', decision_function_shape='ovo')\n",
    "grid_search_poly = GridSearchCV(estimator=svc_poly, param_grid=param_grid_poly, cv=10)\n",
    "grid_search_poly.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Polynomial Kernel - Best Parameters:\", grid_search_poly.best_params_)\n",
    "print(\"Polynomial Kernel - Best Accuracy:\", grid_search_poly.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ea2bcb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters with C tuning: {'C': 100, 'degree': 2, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best Accuracy with C tuning: 0.9281853281853282\n"
     ]
    }
   ],
   "source": [
    "#（4） 松弛系数惩罚项C的调整\n",
    "#在实际应用种，松弛系数惩罚项C和核函数的相关参数（gamma,degree等）往往搭配一起调整，这是SVM调参的重点。可以使用学习曲线或者网格搜索来调整C值。\n",
    "\n",
    "param_grid_C = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid'],\n",
    "    'gamma': [0.01, 0.1, 1],\n",
    "    'degree': [2, 3, 4]  # 仅用于多项式核函数\n",
    "}\n",
    "\n",
    "svc = SVC(decision_function_shape='ovo')\n",
    "grid_search_C = GridSearchCV(estimator=svc, param_grid=param_grid_C, cv=10)\n",
    "grid_search_C.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best Parameters with C tuning:\", grid_search_C.best_params_)\n",
    "print(\"Best Accuracy with C tuning:\", grid_search_C.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
